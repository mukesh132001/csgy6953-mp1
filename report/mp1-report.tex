%File: formatting-instructions-latex-2024.tex
%release 2024.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}


\usepackage{makecell}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
\nocopyright % -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Image Classification with Mini-ResNet}
\author {
    % Authors
    Mike Chaberski
    and
    Mukesh Ethiraj
    and
    Dinesh Sathunuri
}
\affiliations {
    % Affiliations
    NYU Tandon School of Engineering\\
    mac937@nyu.edu, dinesh-tbd@nyu.edu, other-tbd@nyu.edu
}


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    A model with ResNet architecture and less than 5 million trainable parameters is herein designed for the task of
    image classification.
    The model is trained and evaluated on the CIFAR-10 dataset, which contains very small images across ten classes.
    Code is available at https://github.com/mike10004/csgy6953-mp1.
\end{abstract}

\section{Overview}

Image classification, in the context of this machine learning effort, is the task of identifying the content of an image.
Models with a residual network (ResNet) architecture, that is, deep convolutional neural networks containing layers with
skip connections, have shown strong performance in the image classification task.
The original ResNet paper reported 93.5\% accuracy for a model trained and evaluated on the CIFAR-10 dataset~\cite{dblp:2015}.
Example CIFAR images are shown in Figure~\ref{fig1}.

\begin{figure}[b]
\centering
\includegraphics[width=0.95\columnwidth]{cifar-example-images}
\caption{CIFAR images from the frog, car, and dog classes.}
\label{fig1}
\end{figure}

That original research studied models with large numbers of trainable parameters (though the ResNet architecture in
general requires many fewer parameters than standard CNN models to achieve good performance).
The smallest network in the original ResNet paper, ResNet-18, has 11.7 million parameters, according to torch-summary
analysis of the PyTorch ResNet implementation.

This research focuses on designing, training, and evaluating a model with ResNet architecture that has under five
million parameters, aiming to achieve high accuracy on CIFAR-10.
Using model definition and training code adapted from the pytorch-cifar repository of GitHub user kuangliu, model
hyperparameters and training strategies are determined through experimentation on a validation set.
The final model produced from this process achieves accuracy of TBD on the CIFAR-10 test dataset.

\section{Methodology}

To design the optimal model for the task, a series of experiments is performed to determine the best architecture,
hyperparameters, and training strategies such as regularization, learning rate scheduling, and data augmentation.
The CIFAR-10 training dataset is split into 90\% for training and 10\% for validation.
Alternatives are evaluated based on quantitative metrics such as validation accuracy as well as qualitative assessment
of loss curve trends.

\subsection{Architecture}

Our model definition code implements the core ResNet feature of convolutional layers with skip connections as a
pipeline of block sequences, where a block contains two convolutional layers, each with batch normalization, plus the
skip connection.
The number of block sequences in the pipeline and the lengths of the individual block sequences form a descriptor of a
given model architecture.
For example, the ResNet-18 model has four block sequences, each of length 2, and can be identified by the architecture
descriptor 2-2-2-2.

The original ResNet research prefers sequences of at least two blocks.
Architectures with four such block sequences have more than 5 million trainable parameters, thus candidate
architectures for our task must contain at most three sequences.
Based on these constraints, the following candidate architectures are evaluated herein: 2-2-2, 2-4-2, 2-5-2, 2-5-3,
and 3-5-3.
The upstream codebase explicitly required four sequences, so it was adapted to support an arbitrary number of block
sequences.

For these initial experiments, hyperparameters and other training details are drawn from the original ResNet paper and
the upstream repository defaults.
The learning rate is set to 0.1 and models are trained for 40 epochs with Stochastic Gradient Descent (SGD) at a batch
size of 128.
Early experimentation showed that the training has a tendency to reach loss saturation, at which point improvements to
the maximum validation accuracy are merely random fluctuations from a model overfitted to the training data.
Therefore training is stopped by default when training accuracy reaches 99.5\%, and in some experiments, that threshold
is further reduced.

\begin{table}[b]
\centering
%\resizebox{.95\columnwidth}{!}{
\begin{tabular}{|l|r|r|r|r|r|}
    \firsthline
    \makecell[lc]{Architecture} & 2-2-2 & 2-4-2 & 2-4-3 & 2-5-3 & 3-5-3 \\
    \hline
    \makecell[lc]{Validation \\ Accuracy (\%)} & 90.0 & 91.0 & 92.0 & 93.0 & 94.0 \\
    \lasthline
\end{tabular}
%}
\caption{Validation accuracy for various architecture candidates.}
\label{table1}
\end{table}

The results in~\ref{table1} show little differentiation among the validation accuracy rates for the different architectures.
The validation loss is highly volatile for all architectures, so before selecting an architecture, experimentation
with learning rate scheduling will be conducted in order to compare performance of more stable models.

\subsection{Training Strategies}

\subsubsection{Learning Rate Scheduling}

The initial architecture experiments were conducted with a constant learning rate of 0.1.
In the experiments below, this approach is compared to other learning rate scheduling approaches.
Approaches under consideration are: step scheduling, as used by the original ResNet paper; cosine annealing, as
implemented in the upstream codebase; and an adaptive scheduler that reduces the learning rate when validation loss
plateaus.
Training is stopped early if the training accuracy reaches 97.5\%.

INSERT learning rate scheduler experiment results

The results show approximately equal validation accuracy across all strategies.
Because the effect of some regularization strategies discussed below may be entangled with learning rate scheduling,
the adaptive scheduler is selected for those experiments, as it is less likely to require re-tuning.

Re-running the architecture experiment with the optimal learning rate scheduler shows much more stable validation loss,
but the differentiation between architectures with respect to validation accuracy is not substantial.
Therefore we select the 2-2-2 architecture to reduce the risk of overfitting.

\subsubsection{Optimizer}

The optimizer algorithm plays a key role in training, and Adam was considered as an alternative to the default SGD.
However, initial results were not promising.
First, Adam appears to be ineffective at the (somewhat large) learning rate 0.1. Validation loss is extremely volatile
at that learning rate and training loss fails to converge.
At learning rate 0.01 there is some improvement, but the model still fails to achieve more than 60\% validation
accuracy, even when trained to twice as many epochs as a model trained with SGD. More investigation is needed to
determine whether our implementation was flawed, customization of Adam parameters may improve performance, or perhaps
the algorithm is not well-suited to this type of model and/or dataset characteristics.

INSERT Adam loss/accuracy plots, if space allows

\subsubsection{Regularization}

A suboptimal trend in the experiments reported above is that the training loss tends to become saturated while the
validation accuracy is in the low- to mid-90\% range.
When the training loss is saturated, the gradient does not provide adequate signal to adjust the weights.
Subsequent minor increases in validation accuracy at that point are likely the result of random fluctuations as the
model becomes overfitted to the training data.

To reduce overfitting, two strategies for regularization were considered: increasing weight decay, and introducing
dropout into training.
The upstream codebase defaults to weight decay of 0.0005, and the effects of eliminating and increasing weight decay
are evaluated.
To test the effect of dropout, multiple dropout ``layers'' are inserted into the model at the input layer, before and
after the block sequence pipeline, and between each sequence in the block sequence pipeline.
Two dropout strategies are evaluated; in both cases, the input layer dropout rate is 20\%, and dropout rates of 20\%
and 50\% for the hidden layers are evaluated.

INSERT weight decay experiment results

TODO discuss dropout results

INSERT dropout experiment results

TODO discuss dropout results
Additional data augmentation for the purpose of regularization is potentially worth investigating; the current
implementation includes random horizontal flip and random crop with 4 pixels of padding.

\subsection{Hyperparameters}

The 2-2-2 architecture selected from the above analysis was evaluated with three different values for the convolution
kernel size within each block.
The impact of other hyperparameters, such as the number of channels within blocks and the pool size in the average pool
layer, may be worthy of consideration, but their values were fixed at the upstream defaults to reduce the search space
for this investigation.
Experiments were conducted with models trained with convolution kernel sizes of 3 (the default), 5, and 7, and the
results are shown below.

INSERT convolution kernel size experiment results

Kernel size 3 is selected as the optimal kernel size because it achieve the highest validation accuracy.
The effect of varying the kernel size is not large, possibly because the CIFAR image size is quite small (32x32 pixels).

\section{Results}

The analysis above suggests that the best choice of architecture, training strategy, and hyperparameters is the 2-2-2
model with adaptive learning rate scheduler, weight decay 0.0005, 20\% input dropout and 50\% hidden dropout, and
convolution kernel size 3.
This model was trained to 100 epochs, with early stopping of training (at training accuracy 97.5\%) to avoid overfitting.
The checkpoint with the best validation accuracy was selected to be evaluated on the test data.
On the CIFAR-10 test dataset, which contains 10k images, the model's accuracy is TBD.

Most avenues of investigation ended with the choice to use parameters specified by the original ResNet researchers or
the upstream codebase, or to use near equivalents.
This suggests either that those authors had performed adequate tuning already or that further exploration of variables,
with more granular and systematic examination, is warranted.
Grid search with cross validation would be an appropriate technique for such exploration, given sufficient time and
computing resources.

\bibliography{aaai24}

\end{document}
