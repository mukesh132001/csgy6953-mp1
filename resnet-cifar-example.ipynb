{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet Example\n",
    "\n",
    "Model definition and training code is adapted from https://github.com/kuangliu/pytorch-cifar."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23efab9bb6f55e37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(pip show torch-summary >& /dev/null || pip install --quiet torch-summary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ee9d746b26c0d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(test -d .git || test -d mp1 || git clone https://github.com/mike10004/csgy6953-mp1.git mp1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e820aeaa34b95b6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# change to correct branch here, if not main\n",
    "!(test -d mp1 && cd mp1 && git switch flexy-resnet)\n",
    "!(test -d mp1 && cd mp1 && git pull && git rev-parse --short HEAD)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4813fe4b59dd96e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(test -d mp1 && pip install --quiet --editable mp1)\n",
    "import site\n",
    "site.main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879c7fed9ef3dc4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dlmp1\n",
    "import importlib\n",
    "importlib.reload(dlmp1)\n",
    "from pathlib import Path\n",
    "print(\"checked importable:\", dlmp1, \"at\", Path(dlmp1.__file__).parent)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee7d1b8eb60bec2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "# set empty to disable saving\n",
    "# note that the first path component MyDrive is required\n",
    "GDRIVE_SAVE_DIR = \"MyDrive/CS-GY 6953 DL/deep learning midterm project/checkpoints\"\n",
    "\n",
    "def prepare_mount() -> Optional[str]:\n",
    "    save_path_root = \"/content/gdrive\"\n",
    "    local_save_root = str(os.path.join(save_path_root, GDRIVE_SAVE_DIR)) \n",
    "    if GDRIVE_SAVE_DIR:\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount(save_path_root)\n",
    "            return local_save_root\n",
    "        except ImportError:\n",
    "            print(\"(not saving because not in colab environment)\")\n",
    "\n",
    "LOCAL_GDRIVE_SAVE_PATH = prepare_mount()\n",
    "\n",
    "def upload_checkpoint(checkpoint_file: Path, infix: str) -> Optional[str]:\n",
    "    if LOCAL_GDRIVE_SAVE_PATH:\n",
    "        filename = f\"{checkpoint_file.stem}-{infix}{checkpoint_file.suffix}\"\n",
    "        dst_file = os.path.join(LOCAL_GDRIVE_SAVE_PATH, filename)\n",
    "        shutil.copyfile(checkpoint_file, dst_file)\n",
    "        return dst_file\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf64c5b560b420f3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dlmp1.models.resnet import CustomResNet\n",
    "from dlmp1.models.resnet import BlockSpec\n",
    "# noinspection PyPackageRequirements\n",
    "import torchsummary\n",
    "\n",
    "def create_model():\n",
    "    return CustomResNet([\n",
    "        BlockSpec(2, 64, stride=1),\n",
    "        BlockSpec(5, 128, stride=2),\n",
    "        BlockSpec(3, 256, stride=2),\n",
    "    ]) \n",
    "\n",
    "def summarize_model():\n",
    "    model = create_model()\n",
    "    stats = torchsummary.summary(model, verbose=0)\n",
    "    print(type(model).__name__, f\"{stats.trainable_params/1_000_000:.1f}m trainable parameters ({stats.trainable_params})\")\n",
    "    del model\n",
    "\n",
    "summarize_model()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "662aa08adbaaf77a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dlmp1.main import Dataset\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "DATASET = Dataset.acquire(BATCH_SIZE_TRAIN)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94353ad7aa455d61",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dlmp1.main\n",
    "from dlmp1.main import TrainConfig\n",
    "\n",
    "DO_TRAIN = False\n",
    "CONFIG = TrainConfig(\n",
    "    epoch_count=160,\n",
    "    learning_rate=0.1,\n",
    "    seed=987654321\n",
    ")\n",
    "\n",
    "TRAIN_RESULT = None\n",
    "if DO_TRAIN:\n",
    "    TRAIN_RESULT = dlmp1.main.perform(\n",
    "        model_provider=create_model,\n",
    "        dataset=DATASET,\n",
    "        config=CONFIG,\n",
    "    )\n",
    "\n",
    "if TRAIN_RESULT is not None:\n",
    "    CHECKPOINT_DST_PATH = upload_checkpoint(TRAIN_RESULT.checkpoint_file, TRAIN_RESULT.timestamp)\n",
    "    if CHECKPOINT_DST_PATH:\n",
    "        print(f\"copied checkpoint file to\", CHECKPOINT_DST_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1edbd841bec01013",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
