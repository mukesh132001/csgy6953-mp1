{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet Example\n",
    "\n",
    "Model definition and training code is adapted from https://github.com/kuangliu/pytorch-cifar."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23efab9bb6f55e37"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(pip show torch-summary >& /dev/null || pip install --quiet torch-summary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ee9d746b26c0d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(test -d .git || test -d mp1 || git clone https://github.com/mike10004/csgy6953-mp1.git mp1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e820aeaa34b95b6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# change to correct branch here\n",
    "!(test -d mp1 && cd mp1 && git switch main)\n",
    "!(test -d mp1 && cd mp1 && git pull && git rev-parse --short HEAD)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4813fe4b59dd96e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!(test -d mp1 && pip install --quiet --editable mp1)\n",
    "import site\n",
    "site.main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879c7fed9ef3dc4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dlmp1\n",
    "import importlib\n",
    "importlib.reload(dlmp1)\n",
    "from pathlib import Path\n",
    "print(\"checked importable:\", dlmp1, \"at\", Path(dlmp1.__file__).parent)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee7d1b8eb60bec2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "# set empty to disable saving\n",
    "# note that the first path component MyDrive is required\n",
    "GDRIVE_SAVE_DIR = \"MyDrive/CS-GY 6953 DL/deep learning midterm project/checkpoints\"\n",
    "\n",
    "def prepare_mount() -> Optional[str]:\n",
    "    save_path_root = \"/content/gdrive\"\n",
    "    local_save_root = str(os.path.join(save_path_root, GDRIVE_SAVE_DIR)) \n",
    "    if GDRIVE_SAVE_DIR:\n",
    "        try:\n",
    "            from google.colab import drive\n",
    "            drive.mount(save_path_root)\n",
    "            return local_save_root\n",
    "        except ImportError:\n",
    "            print(\"(not saving because not in colab environment)\")\n",
    "\n",
    "LOCAL_GDRIVE_SAVE_PATH = prepare_mount()\n",
    "\n",
    "def upload_checkpoint(checkpoint_file: Path, infix: str) -> Optional[str]:\n",
    "    if LOCAL_GDRIVE_SAVE_PATH:\n",
    "        filename = f\"{checkpoint_file.stem}-{infix}{checkpoint_file.suffix}\"\n",
    "        dst_file = os.path.join(LOCAL_GDRIVE_SAVE_PATH, filename)\n",
    "        shutil.copyfile(checkpoint_file, dst_file)\n",
    "        return dst_file\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf64c5b560b420f3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dlmp1.models.resnet import CustomResNet\n",
    "from dlmp1.models.resnet import BlockSpec\n",
    "# noinspection PyPackageRequirements\n",
    "import torchsummary\n",
    "\n",
    "def create_model():\n",
    "    return CustomResNet([\n",
    "        BlockSpec(2, 64, stride=1),\n",
    "        BlockSpec(5, 128, stride=2),\n",
    "        BlockSpec(3, 256, stride=2),\n",
    "    ]) \n",
    "\n",
    "def summarize_model():\n",
    "    model = create_model()\n",
    "    stats = torchsummary.summary(model, verbose=0)\n",
    "    print(type(model).__name__, f\"{stats.trainable_params/1_000_000:.1f}m trainable parameters ({stats.trainable_params})\")\n",
    "    del model\n",
    "\n",
    "summarize_model()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "662aa08adbaaf77a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dlmp1.train import Partitioning\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "DATASET = Partitioning.prepare(BATCH_SIZE_TRAIN, random_seed=12345)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94353ad7aa455d61",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dlmp1.train\n",
    "from dlmp1.train import TrainConfig\n",
    "\n",
    "DO_SELECT_MODEL = False\n",
    "\n",
    "def select_model():\n",
    "    raise NotImplemented() "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbace51fb2c65bc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DO_TRAIN = False\n",
    "CONFIG = TrainConfig(\n",
    "    epoch_count=60,\n",
    "    learning_rate=0.1,\n",
    "    # lr_scheduler_spec=\"step:gamma=0.1;step_size=40\",\n",
    "    seed=987654321,\n",
    ")\n",
    "\n",
    "print(json.dumps(CONFIG._asdict(), indent=2))\n",
    "\n",
    "TRAIN_RESULT = None\n",
    "if DO_TRAIN:\n",
    "    TRAIN_RESULT = dlmp1.train.perform(\n",
    "        model_provider=create_model,\n",
    "        dataset=DATASET,\n",
    "        config=CONFIG,\n",
    "    )\n",
    "\n",
    "if TRAIN_RESULT is not None:\n",
    "    CHECKPOINT_DST_PATH = upload_checkpoint(TRAIN_RESULT.checkpoint_file, TRAIN_RESULT.timestamp)\n",
    "    if CHECKPOINT_DST_PATH:\n",
    "        print(f\"copied checkpoint file to\", CHECKPOINT_DST_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1edbd841bec01013",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from dlmp1.train import History\n",
    "\n",
    "\n",
    "def plot_epochs_curves(train_hist: History, val_hist: History):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    for ax, measurements, factor, y_bounds, subject, y_label in zip(axes, \n",
    "                                               [(train_hist.losses, val_hist.losses), (train_hist.accs, val_hist.accs)],\n",
    "                                               [1.0, 100.0],\n",
    "                                               [None, (0.0, 100.0)],\n",
    "                                               [\"Loss\", \"Accuracy\"],\n",
    "                                               [\"Cross-Entropy Loss\", \"Correct (%)\"]):\n",
    "        ax: Axes\n",
    "        ax.set_title(subject)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        train_values, val_values = measurements\n",
    "        train_values, val_values = np.array(train_values), np.array(val_values)\n",
    "        epochs = list(range(max(len(train_values), len(val_values))))\n",
    "        ax.plot(epochs, train_values * factor, label=f\"Train {subject}\")\n",
    "        ax.plot(epochs, val_values * factor, label=f\"Validation {subject}\")\n",
    "        ax.legend()\n",
    "        if y_bounds is not None:\n",
    "            ax.set_ylim(*y_bounds)\n",
    "    plt.show()\n",
    "\n",
    "if TRAIN_RESULT is not None:\n",
    "    plot_epochs_curves(TRAIN_RESULT.train_history, TRAIN_RESULT.val_history)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1f0ddb45aef946b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import dlmp1.train\n",
    "\n",
    "def evaluate_test_set():\n",
    "    if not TRAIN_RESULT:\n",
    "        return\n",
    "    testset_loader = Partitioning.prepare_test_loader(batch_size=100)\n",
    "    inference = dlmp1.train.inference_all(\n",
    "        TRAIN_RESULT.model, \n",
    "        TRAIN_RESULT.device, \n",
    "        testset_loader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    print()\n",
    "    print(f\"{inference.accuracy() * 100:.2f}% is accuracy on test set ({inference.correct}/{inference.total})\")\n",
    "\n",
    "evaluate_test_set()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4917c571031f5c23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
