{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet Example\n",
    "\n",
    "Model definition and training code is adapted from https://github.com/kuangliu/pytorch-cifar."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23efab9bb6f55e37"
  },
  {
   "cell_type": "code",
   "source": [
    "!(pip show torch-summary >& /dev/null || pip install --quiet torch-summary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ee9d746b26c0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!(test -d .git || test -d mp1 || git clone https://github.com/mike10004/csgy6953-mp1.git mp1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e820aeaa34b95b6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# change to correct branch here\n",
    "!(test -d mp1 && cd mp1 && git switch select-2)\n",
    "!(test -d mp1 && cd mp1 && git pull && git rev-parse --short HEAD)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4813fe4b59dd96e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!(test -d mp1 && pip install --quiet --editable mp1)\n",
    "import site\n",
    "site.main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879c7fed9ef3dc4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import dlmp1\n",
    "import importlib\n",
    "importlib.reload(dlmp1)\n",
    "from pathlib import Path\n",
    "print(\"checked importable:\", dlmp1, \"at\", Path(dlmp1.__file__).parent)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee7d1b8eb60bec2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "# set empty to disable saving\n",
    "# note that the first path component MyDrive is required\n",
    "GDRIVE_SAVE_DIR = \"MyDrive/CS-GY 6953 DL/deep learning midterm project/checkpoints\"\n",
    "\n",
    "class Uploader:\n",
    "    \n",
    "    def __init__(self, local_gdrive_save_path: Optional[str] = None):\n",
    "        self.local_gdrive_save_path = local_gdrive_save_path\n",
    "\n",
    "    def upload_file(self, src_file: Path, dst_path: str, suppress_error: bool = False) -> Optional[str]:\n",
    "        if not self.local_gdrive_save_path:\n",
    "            return\n",
    "        dst_file = Path(self.local_gdrive_save_path) / dst_path\n",
    "        try:\n",
    "            dst_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "            shutil.copyfile(src_file, dst_file)\n",
    "            return str(dst_file)\n",
    "        except Exception as e:\n",
    "            if suppress_error:\n",
    "                print(f\"suppressing save error {type(e)} {e} on file {src_file} -> {dst_file}\", file=sys.stderr)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    def upload_checkpoint(self, checkpoint_file: Path, infix: str) -> Optional[str]:\n",
    "        if not self.local_gdrive_save_path:\n",
    "            return\n",
    "        filename = f\"{checkpoint_file.stem}-{infix}{checkpoint_file.suffix}\"\n",
    "        dst_file = self.upload_file(checkpoint_file, filename)\n",
    "        return dst_file\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_mount() -> 'Uploader':\n",
    "        save_path_root = \"/content/gdrive\"\n",
    "        local_save_root = str(os.path.join(save_path_root, GDRIVE_SAVE_DIR)) \n",
    "        if GDRIVE_SAVE_DIR:\n",
    "            try:\n",
    "                # noinspection PyUnresolvedReferences\n",
    "                from google.colab import drive\n",
    "                drive.mount(save_path_root)\n",
    "                return Uploader(local_save_root)\n",
    "            except Exception as e:\n",
    "                if isinstance(e, ImportError):\n",
    "                    print(\"(not saving because not in colab environment)\")\n",
    "                else:\n",
    "                    print(\"not saving to gdrive due to\", type(e).__name__, e)\n",
    "\n",
    "UPLOADER = Uploader.prepare_mount()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf64c5b560b420f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from dlmp1.models.resnet import CustomResNetWithDropout\n",
    "from dlmp1.models.resnet import Hyperparametry\n",
    "from dlmp1.models.resnet import BlockSpec\n",
    "# noinspection PyPackageRequirements\n",
    "import torchsummary\n",
    "\n",
    "def create_model():\n",
    "    hyperparametry = Hyperparametry(\n",
    "        pre_blocks_dropout_rate=0.5, \n",
    "        post_blocks_dropout_rate=0.5,\n",
    "        between_blocks_dropout_rate=0.5,\n",
    "    )\n",
    "    return CustomResNetWithDropout([\n",
    "        BlockSpec(2, 64, stride=1),\n",
    "        BlockSpec(5, 128, stride=2),\n",
    "        BlockSpec(3, 256, stride=2),\n",
    "    ], hyperparametry=hyperparametry) \n",
    "\n",
    "def summarize_model():\n",
    "    model = create_model()\n",
    "    stats = torchsummary.summary(model, verbose=0)\n",
    "    print(type(model).__name__, f\"{stats.trainable_params/1_000_000:.1f}m trainable parameters ({stats.trainable_params})\")\n",
    "    del model\n",
    "\n",
    "summarize_model()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "662aa08adbaaf77a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from dlmp1.train import Partitioning\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "DATASET = Partitioning.prepare(BATCH_SIZE_TRAIN, random_seed=12345)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94353ad7aa455d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from dlmp1.train import History\n",
    "\n",
    "\n",
    "def plot_epochs_curves(train_hist: History, val_hist: History, title: Optional[str] = None):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    fig: Figure\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    for ax, measurements, factor, y_bounds, subject, y_label in zip(axes, \n",
    "                                               [(train_hist.losses, val_hist.losses), (train_hist.accs, val_hist.accs)],\n",
    "                                               [1.0, 100.0],\n",
    "                                               [None, (0.0, 100.0)],\n",
    "                                               [\"Loss\", \"Accuracy\"],\n",
    "                                               [\"Cross-Entropy Loss\", \"Correct (%)\"]):\n",
    "        ax: Axes\n",
    "        ax.set_title(subject)\n",
    "        ax.set_xlabel(\"Epochs\")\n",
    "        ax.set_ylabel(y_label)\n",
    "        train_values, val_values = measurements\n",
    "        train_values, val_values = np.array(train_values), np.array(val_values)\n",
    "        epochs = list(range(max(len(train_values), len(val_values))))\n",
    "        ax.plot(epochs, train_values * factor, label=f\"Train {subject}\")\n",
    "        ax.plot(epochs, val_values * factor, label=f\"Validation {subject}\")\n",
    "        ax.legend()\n",
    "        if y_bounds is not None:\n",
    "            ax.set_ylim(*y_bounds)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "276bf9803d9c3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import io\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "import tabulate\n",
    "\n",
    "import dlmp1.train\n",
    "import dlmp1.utils\n",
    "from dlmp1.train import TrainConfig\n",
    "from dlmp1.train import EpochInference\n",
    "from dlmp1.select import iterate_model_factories\n",
    "from dlmp1.select import iterate_selectables\n",
    "\n",
    "DO_SELECT_MODEL = False\n",
    "\n",
    "class TrainingManager:\n",
    "    \n",
    "    def __init__(self, progress_bar: Optional[tqdm] = None, progress_desc_prefix: Optional[str] = None):\n",
    "        self.saturation_threshold = 0.995\n",
    "        self.progress_bar = progress_bar\n",
    "        self.progress_desc_prefix = progress_desc_prefix or \"\"\n",
    "        self.max_val_acc = None\n",
    "\n",
    "    def maybe_stop_training(self, epoch: int, lr: Any, train_inf: EpochInference, val_inf: EpochInference):\n",
    "        if self.progress_bar is not None:\n",
    "            self.progress_bar.update(1)\n",
    "            acc_report = val_inf.accuracy()\n",
    "            if self.max_val_acc is None or acc_report > self.max_val_acc:\n",
    "                self.max_val_acc = acc_report \n",
    "                desc = f\"{self.progress_desc_prefix}acc {acc_report:1.2f}\"\n",
    "                self.progress_bar.set_description(desc)\n",
    "        train_acc = train_inf.accuracy()\n",
    "        if train_acc >= self.saturation_threshold:\n",
    "            return f\"training accuracy saturated ({train_acc*100:.1f}%) at epoch {epoch} with learning rate {lr}\"\n",
    "    \n",
    "\n",
    "def select_model():\n",
    "    tag = dlmp1.utils.timestamp()\n",
    "    selection_group_path = f\"model-selection/{tag}\"\n",
    "    readme = io.StringIO()\n",
    "    def _record(*args):\n",
    "        print(*args, file=readme)\n",
    "    _record(\"tag\", tag)\n",
    "    structures = [\n",
    "        # [2, 1, 1, 1],\n",
    "        # [2, 2, 2],\n",
    "        # [2, 4, 2],\n",
    "        # [2, 5, 2],\n",
    "        # [2, 5, 3],\n",
    "        [3, 5, 3],\n",
    "        # [2, 3, 2],\n",
    "        # [2, 4, 3],\n",
    "        # [3, 4, 3],\n",
    "    ]\n",
    "    hyperparametries = [\n",
    "        Hyperparametry(),\n",
    "        Hyperparametry(input_layer_dropout_rate=0.2),\n",
    "        Hyperparametry(input_layer_dropout_rate=0.2, pre_blocks_dropout_rate=0.2, between_blocks_dropout_rate=0.2, post_blocks_dropout_rate=0.2),\n",
    "        Hyperparametry(input_layer_dropout_rate=0.2, pre_blocks_dropout_rate=0.5, between_blocks_dropout_rate=0.5, post_blocks_dropout_rate=0.5),\n",
    "    ]\n",
    "    factories = iterate_model_factories(structures, hyperparametries)\n",
    "    epochs = 40\n",
    "    configs = [        \n",
    "        TrainConfig(\n",
    "            epoch_count=epochs, \n",
    "            checkpoint_file=\"auto\", \n",
    "            learning_rate=0.1,\n",
    "            lr_scheduler_spec=\"plateau:factor=0.75;patience=5;threshold=0.05;threshold_mode=abs\",\n",
    "            seed=45678, \n",
    "            optimizer_type=\"sgd\", \n",
    "            quiet=True,\n",
    "        ) \n",
    "    ]\n",
    "    selectables = list(iterate_selectables(\n",
    "        factories,\n",
    "        configs,\n",
    "    ))\n",
    "    selectable_best_val_accs = []\n",
    "    for selectable_index, selectable in enumerate(selectables):\n",
    "        prefix = f\"model {selectable_index+1}/{len(selectables)} \"\n",
    "        title = selectable.description or getattr(selectable.model_factory, \"description\", \"\")\n",
    "        print(prefix, title)\n",
    "        progress_bar = tqdm(total=selectable.train_config.epoch_count, desc=prefix, file=sys.stdout, position=0, leave=True)\n",
    "        training_manager = TrainingManager(progress_bar, progress_desc_prefix=prefix)\n",
    "        train_result = dlmp1.train.perform(\n",
    "            model_provider=selectable.model_factory,\n",
    "            dataset=DATASET,\n",
    "            config=selectable.train_config,\n",
    "            callback=training_manager.maybe_stop_training\n",
    "        )\n",
    "        progress_bar.close()\n",
    "        if train_result.early_stop_reason:\n",
    "            print(\"training terminated early:\", train_result.early_stop_reason)\n",
    "        print(\"training duration:\", train_result.duration_readable())\n",
    "        uploaded_file = UPLOADER.upload_file(train_result.checkpoint_file, \n",
    "                    f\"{selection_group_path}/{selectable_index+1}-{train_result.checkpoint_file.name}\", \n",
    "                    suppress_error=True)\n",
    "        print(\"uploaded\", uploaded_file)\n",
    "        best_val_acc = max(train_result.val_history.accs, default=0)\n",
    "        _record(prefix, Path(uploaded_file).name, f\"{best_val_acc*100:.2f}\", title)\n",
    "        selectable_best_val_accs.append((best_val_acc, train_result.checkpoint_file, title))\n",
    "        plot_epochs_curves(\n",
    "            train_result.train_history, \n",
    "            train_result.val_history, \n",
    "            title=title or f\"S{selectable_index+1} {train_result.checkpoint_file.stem}\",\n",
    "        )\n",
    "    print()\n",
    "    acc_table = tabulate.tabulate(selectable_best_val_accs, headers=[\"validation acc\", \"checkpoint\", \"title\"])\n",
    "    print(acc_table)\n",
    "    _record(acc_table)\n",
    "    readme_file = Path(\"/tmp/select-model-info.txt\")\n",
    "    readme_file.write_text(readme.getvalue())\n",
    "    UPLOADER.upload_file(readme_file, f\"{selection_group_path}/{readme_file.name}\", suppress_error=True)\n",
    "\n",
    "if DO_SELECT_MODEL:\n",
    "    select_model()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbace51fb2c65bc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "DO_TRAIN = False\n",
    "CONFIG = TrainConfig(\n",
    "    epoch_count=100,\n",
    "    learning_rate=0.1,\n",
    "    lr_scheduler_spec=\"step:gamma=0.9;step_size=25\",\n",
    "    seed=987654321,\n",
    ")\n",
    "\n",
    "print(json.dumps(CONFIG._asdict(), indent=2))\n",
    "\n",
    "TRAIN_RESULT = None\n",
    "if DO_TRAIN:\n",
    "    TRAIN_RESULT = dlmp1.train.perform(\n",
    "        model_provider=create_model,\n",
    "        dataset=DATASET,\n",
    "        config=CONFIG,\n",
    "    )\n",
    "\n",
    "if TRAIN_RESULT is not None:\n",
    "    CHECKPOINT_DST_PATH = UPLOADER.upload_checkpoint(TRAIN_RESULT.checkpoint_file, TRAIN_RESULT.timestamp)\n",
    "    if CHECKPOINT_DST_PATH:\n",
    "        print(f\"copied checkpoint file to\", CHECKPOINT_DST_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1edbd841bec01013",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "if TRAIN_RESULT is not None:\n",
    "    plot_epochs_curves(TRAIN_RESULT.train_history, TRAIN_RESULT.val_history)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1f0ddb45aef946b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import dlmp1.train\n",
    "\n",
    "def evaluate_test_set():\n",
    "    if not TRAIN_RESULT:\n",
    "        return\n",
    "    testset_loader = Partitioning.prepare_test_loader(batch_size=100)\n",
    "    inference = dlmp1.train.inference_all(\n",
    "        TRAIN_RESULT.model, \n",
    "        TRAIN_RESULT.device, \n",
    "        testset_loader,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    print()\n",
    "    print(f\"{inference.accuracy() * 100:.2f}% is accuracy on test set ({inference.correct}/{inference.total})\")\n",
    "\n",
    "evaluate_test_set()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4917c571031f5c23",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
